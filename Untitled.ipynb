{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd70306-76a0-4a11-9f26-56cc13ff837c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLTK_DATA=./data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mginn/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/mginn/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:529: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading corpus...\n",
      "Loaded 2141 texts.\n"
     ]
    }
   ],
   "source": [
    "%env CLTK_DATA=./data\n",
    "\n",
    "from src.corpus import load_corpus, download_corpus\n",
    "# download_corpus()\n",
    "documents = load_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b085ad",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for chunk range(0, 535)...\n",
      "\n",
      "â€Žð¤€ CLTK version '1.1.6'.Creating embeddings for chunk range(535, 1070)...\n",
      "\n",
      "â€Žð¤€ CLTK version '1.1.6'.Creating embeddings for chunk range(1070, 1605)...\n",
      "\n",
      "\n",
      "â€Žð¤€ CLTK version '1.1.6'.Creating embeddings for chunk range(1605, 2140)...\n",
      "\n",
      "\n",
      "Pipeline for language 'Latin' (ISO: 'lat'): `LatinNormalizeProcess`, `LatinStanzaProcess`, `LatinEmbeddingsProcess`, `StopsProcess`, `LatinLexiconProcess`.\n",
      "â€Žð¤€ CLTK version '1.1.6'.\n",
      "Created NLP pipeline.\n",
      "\n",
      "Pipeline for language 'Latin' (ISO: 'lat'): `LatinNormalizeProcess`, `LatinStanzaProcess`, `LatinEmbeddingsProcess`, `StopsProcess`, `LatinLexiconProcess`.Computing document embeddings...\n",
      "\n",
      "Created NLP pipeline.\n",
      "Task 3: 0/535\n",
      "Computing document embeddings...Pipeline for language 'Latin' (ISO: 'lat'): `LatinNormalizeProcess`, `LatinStanzaProcess`, `LatinEmbeddingsProcess`, `StopsProcess`, `LatinLexiconProcess`.\n",
      "Pipeline for language 'Latin' (ISO: 'lat'): `LatinNormalizeProcess`, `LatinStanzaProcess`, `LatinEmbeddingsProcess`, `StopsProcess`, `LatinLexiconProcess`.\n",
      "Created NLP pipeline.\n",
      "Task 4: 0/535\n",
      "Computing document embeddings...\n",
      "Task 1: 0/535\n",
      "\n",
      "Created NLP pipeline.\n",
      "Computing document embeddings...\n",
      "Task 2: 0/535\n"
     ]
    }
   ],
   "source": [
    "from src.embedder import compute_document_embeddings\n",
    "import multiprocessing\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "all_embeddings = dict()\n",
    "\n",
    "def compute_some_embeddings(position, lock, index_range):\n",
    "    with lock:\n",
    "        print(f\"Creating embeddings for chunk {index_range}...\\n\")\n",
    "    embeddings = compute_document_embeddings(documents[index_range.start:index_range.stop], position, lock) \n",
    "    with lock:\n",
    "        all_embeddings[position] = embeddings\n",
    "        print(f\"Finished embeddings for chunk {position}\")\n",
    "    \n",
    "    \n",
    "num_threads = 4\n",
    "chunk_size = int(len(documents) / num_threads)\n",
    "\n",
    "lock = multiprocessing.Manager().Lock()\n",
    "with multiprocessing.Pool(num_threads) as pool:\n",
    "    start_index = 0\n",
    "    \n",
    "    for position in range(num_threads):\n",
    "        pool.apply_async(compute_some_embeddings, args = (position + 1, lock, range(start_index, start_index + chunk_size)))\n",
    "        start_index += chunk_size\n",
    "                         \n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fe0cd-069d-4c51-8039-b4552be745a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
